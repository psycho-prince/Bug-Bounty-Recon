name: OpenAI Recon – Parallel Zero-Credit Bug Hunt – 2026 Edition

# Trigger manually
on:
  workflow_dispatch:

jobs:
  sora-social-recon:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Create evidence directory
        run: mkdir -p evidence/sora

      - name: Fetch Sora main page & extract JS chunks
        run: |
          curl -s -A "Mozilla/5.0 ReconBot" https://sora.com \
            | grep -oE '(/static/chunks/[^"]+\.js|/static/js/[^"]+\.js|_next/static/chunks/[^"]+)' \
            | sort -u > evidence/sora/sora_js_chunks.txt || true
          echo "Found $(wc -l < evidence/sora/sora_js_chunks.txt) JS chunks"

      - name: Scan Sora chunks for IDOR/social keywords
        run: |
          echo "Scanning for IDOR-prone strings (cameo, draft, group, character, consent)..."
          head -n 15 evidence/sora/sora_js_chunks.txt | while read -r chunk; do
            full_url="https://sora.com${chunk}"
            echo "→ Scraping $full_url"
            curl -s -m 20 -A "Mozilla/5.0 ReconBot" "$full_url" \
              | grep -iE 'cameo_id|character_id|draft_id|group_id|permission|block|consent|revoke|remix|feed|likeness|dm|private_group' \
              >> evidence/sora/sora_idor_strings.txt || true
          done
          sort -u evidence/sora/sora_idor_strings.txt > evidence/sora/sora_idor_unique.txt
          echo "Unique matches: $(wc -l < evidence/sora/sora_idor_unique.txt)"

      - name: Upload Sora artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: sora-recon
          path: evidence/sora/
          retention-days: 14

  atlas-browser-recon:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Create evidence directory
        run: mkdir -p evidence/atlas

      - name: Fetch Atlas/ChatGPT pages & extract keywords
        run: |
          curl -s -A "Mozilla/5.0 ReconBot" https://chatgpt.com/atlas \
            | tee evidence/atlas/atlas_raw.html \
            | grep -iE 'atlas|agent_mode|sandbox|filesystem|local|file://|prompt-injection|bridge|memory|escape|agentic' \
            >> evidence/atlas/atlas_keywords.txt || true
          curl -s -I https://chatgpt.com/atlas 2>&1 >> evidence/atlas/atlas_headers.txt || true
          echo "Atlas keywords found: $(wc -l < evidence/atlas/atlas_keywords.txt)"

      - name: Upload Atlas artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: atlas-recon
          path: evidence/atlas/
          retention-days: 14

  third-party-leaks-recon:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Create evidence directory
        run: mkdir -p evidence/leaks

      - name: Scrape GitHub for OpenAI leaks
        run: |
          echo "Searching GitHub for exposed OpenAI data (API keys, codenames, creds)..."
          queries=("openai api key" "openai internal codename" "openai employee credential" "openai customer data" "openai notion leak" "openai slack bot config")
          for q in "${queries[@]}"; do
            encoded_q=$(echo "$q" | sed 's/ /+/g')
            curl -s -A "Mozilla/5.0 ReconBot" "https://github.com/search?q=${encoded_q}&type=code" \
              | grep -iE 'openai|api_key|token|credential|codename|project|leak|notion|jira|slack|trello|stripe' \
              >> evidence/leaks/github_leaks.txt || true
          done
          sort -u evidence/leaks/github_leaks.txt > evidence/leaks/github_leaks_unique.txt
          echo "Unique leak matches: $(wc -l < evidence/leaks/github_leaks_unique.txt)"

      - name: Upload leaks artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: third-party-leaks
          path: evidence/leaks/
          retention-days: 14

  unreleased-features-recon:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Create evidence directory
        run: mkdir -p evidence/unreleased

      - name: Fetch OpenAI main assets & scan for rumors
        run: |
          curl -s -A "Mozilla/5.0 ReconBot" https://openai.com \
            | grep -oE '(/static/chunks/[^"]+\.js|/static/js/[^"]+\.js)' \
            | sort -u > evidence/unreleased/openai_js_chunks.txt || true
          head -n 10 evidence/unreleased/openai_js_chunks.txt | while read -r chunk; do
            full_url="https://openai.com${chunk}"
            curl -s -m 20 -A "Mozilla/5.0 ReconBot" "$full_url" \
              | grep -iE 'gpt-6|o4|strawberry|audio-model|jony-device|chatgpt-ads|custom-chips|health-bench|frontier-science|gpt-5.3|secret-project' \
              >> evidence/unreleased/unreleased_strings.txt || true
          done
          sort -u evidence/unreleased/unreleased_strings.txt > evidence/unreleased/unreleased_unique.txt
          echo "Unique unreleased matches: $(wc -l < evidence/unreleased/unreleased_unique.txt)"

      - name: Upload unreleased artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: unreleased-features
          path: evidence/unreleased/
          retention-days: 14

  summary:
    runs-on: ubuntu-latest
    if: always()
    steps:
      - name: Download all artifacts
        uses: actions/download-artifact@v4

      - name: Generate overall summary
        run: |
          echo "=== OVERALL RECON SUMMARY ==="
          echo "Sora IDOR matches: $(find . -name 'sora_idor_unique.txt' -exec wc -l {} \; || echo 0)"
          echo "Atlas sandbox keywords: $(find . -name 'atlas_keywords.txt' -exec wc -l {} \; || echo 0)"
          echo "Third-party leaks: $(find . -name 'github_leaks_unique.txt' -exec wc -l {} \; || echo 0)"
          echo "Unreleased features: $(find . -name 'unreleased_unique.txt' -exec wc -l {} \; || echo 0)"
          echo "Download individual artifacts for details!"

      - name: Upload summary
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: recon-summary
          path: . # Uploads everything, but focus on logs
          retention-days: 14
