name: OpenAI-Max-Coverage-Security-Engine

on:
  workflow_dispatch:
    inputs:
      target_domain:
        description: 'Domain to hunt (e.g., openai.com)'
        required: true
        default: 'openai.com'

jobs:
  security-intel:
    runs-on: ubuntu-latest
    timeout-minutes: 180

    steps:
    - name: Checkout
      uses: actions/checkout@v4

    - name: Install System Dependencies
      run: |
        sudo apt update
        sudo apt install -y jq parallel nmap dnsutils libpcap-dev build-essential

    - name: Install Full Arsenal
      run: |
        go install -v github.com/projectdiscovery/subfinder/v2/cmd/subfinder@latest
        go install -v github.com/projectdiscovery/httpx/cmd/httpx@latest
        go install -v github.com/projectdiscovery/katana/cmd/katana@latest
        go install -v github.com/projectdiscovery/nuclei/v3/cmd/nuclei@latest
        go install -v github.com/projectdiscovery/naabu/v2/cmd/naabu@latest
        go install -v github.com/ffuf/ffuf/v2@latest
        pip install arjun
        sudo mv ~/go/bin/* /usr/local/bin/

    # ---------------- RECON PHASE ----------------

    - name: Asset Discovery
      run: |
        echo "${{ github.event.inputs.target_domain }}" > scope.txt
        subfinder -dL scope.txt -all -silent -o subs.txt
        sudo naabu -list subs.txt -top-ports 1000 -silent -o ports.txt
        # Using -o live.txt for the dirty log, but we will clean it next
        httpx -list ports.txt -sc -cl -title -td -silent -o live.txt

    - name: Surface Mapping (Cleaned)
      run: |
        # 1. Katana deep crawl
        katana -list live.txt -jc -kf all -d 3 -rl 20 -o endpoints.txt

        # 2. CRITICAL FIX: Strip EVERYTHING except the URL for Arjun
        # This removes [200], [Cloudflare], and weird brackets that cause IPv6 errors
        grep -oP 'https?://[^\s\[\]]+' live.txt | sort -u > arjun_targets.txt
        
        # 3. Run Arjun (with stability flags and non-blocking error handling)
        if [ -s arjun_targets.txt ]; then
          arjun -i arjun_targets.txt --stable -t 10 -oT params.txt || echo "Arjun encountered some errors but continuing..."
        else
          echo "No targets found for Arjun." > params.txt
        fi

    # ---------------- EXPLOITATION PHASE ----------------

    - name: Deep 403/404 Bypass Sweep
      run: |
        # Ensure we only pass URLs to httpx bypass
        grep -oP 'https?://[^\s\[\]]+' endpoints.txt | sort -u > clean_endpoints.txt
        httpx -list clean_endpoints.txt -path "//" \
          -H "X-OpenAI-Internal: true" \
          -H "X-Forwarded-For: 127.0.0.1" \
          -H "X-Original-URL: /" \
          -sc -cl -title -o bypass_findings.txt

    - name: High-CVE Vulnerability Sweep
      run: |
        # Clean targets for Nuclei
        grep -oP 'https?://[^\s\[\]]+' live.txt | sort -u > nuclei_targets.txt
        nuclei -list nuclei_targets.txt -severity critical,high,medium \
          -tags cve,rce,auth-bypass,exposure,takeover \
          -rl 50 -o nuclei_findings.txt

    # ---------------- REPORTING PHASE ----------------

    - name: Package & Upload Evidence
      run: |
        mkdir -p results
        cp *.txt results/ || true
        cp *.json results/ || true
        # Build a quick summary so you don't have to download the zip to see hits
        echo "# BUG HUNT SUMMARY" > results/SUMMARY.md
        echo "## ðŸŽ¯ Bypasses Found (200 OK)" >> results/SUMMARY.md
        grep "200" results/bypass_findings.txt >> results/SUMMARY.md || echo "None" >> results/SUMMARY.md
        tar -czf security-results.tar.gz results

    - name: Upload Results
      uses: actions/upload-artifact@v4
      with:
        name: max-coverage-results
        path: security-results.tar.gz
        retention-days: 5
        
